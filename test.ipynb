{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cddd16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "keys = ['采集时间', '水温', 'pH', '溶解氧', '电导率', '浊度', '高锰酸盐指数','氨氮', '总磷', '总氮']\n",
    "en_keys = ['WaterTemperature', 'PH' ,'dissolved oxygen', 'Conductivity','Turbidity','PermanganateIndex',\n",
    "        'AmmoniaNitrogen','TP','TN', 'humidity','room temperature','chlorophyll','Algae density']\n",
    "# limits = [(5, 30), (5.0, 9), (1, 15), (50, 500), (0, 1500), (0, 15), (0, 0.5), (0, 0.3), (0, 5)]\n",
    "\n",
    "np.set_printoptions(formatter = {'float': '{:.2f}'.format})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c7e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = datetime.strptime('2021-01-01', '%Y-%m-%d') - timedelta(days=3)\n",
    "df = data_factory('./original_data/05-涪江/涪江水质断面水质-小时尺度/两河审核数据查询表.xls',\n",
    "                  3, 5, 3)\n",
    "df.loc[str(a): '2021-01-01'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trainer import *\n",
    "from models import *\n",
    "\n",
    "\n",
    "def preHandler(ckpt_path, df_path, pre_start_date, model_kwargs, describe_df_path, read_method, *args):\n",
    "    '''\n",
    "    Make Sure the excel file has no nan value.\n",
    "    '''\n",
    "    df = read_method(df_path, *args)\n",
    "    describe = pd.read_csv(describe_df_path, index_col=0)\n",
    "    pre_start_date = datetime.strptime(pre_start_date, '%Y-%m-%d')\n",
    "    end_date = str(pre_start_date - timedelta(days=1))\n",
    "    start_date = str(pre_start_date - timedelta(days=4))\n",
    "    vals = df.loc[start_date:end_date].values[:-1]\n",
    "    if np.isnan(vals).any() or vals.shape[0] != model_kwargs['lGet']:\n",
    "        print('Attention!')\n",
    "        print(f'The excel file has not enough data during {start_date} and {end_date}.')\n",
    "        print(f'Please try another date or change the excel file')\n",
    "        return \n",
    "    \n",
    "    means = describe.loc['mean'].values.reshape(1, 1, 9)\n",
    "    stds = describe.loc['std'].values.reshape(1, 1, 9)\n",
    "    descaler = lambda x: x * stds + means\n",
    "    scaler = lambda x: (x - means) / stds\n",
    "    \n",
    "    model = SCIModule(**model_kwargs)\n",
    "    vals = vals.reshape(1, -1, 9)\n",
    "    vals = scaler(vals)\n",
    "    pre = prediction(ckpt_path, model, vals, model_kwargs['lPre'], model_kwargs['lGet'])\n",
    "    pre = descaler(pre.transpose())\n",
    "    return pre\n",
    "\n",
    "def pre_with_vals(ckpt_path, vals, model_kwargs, describe_of_path, lGet=18):\n",
    "    l, f = vals.shape\n",
    "    if l != lGet or f != 9:\n",
    "        print('The input data should have shape (18, 9)!')\n",
    "        return \n",
    "    if np.isnan(vals).any():\n",
    "        print('Illegal values in data!')\n",
    "        return \n",
    "    describe = pd.read_csv(describe_df_path, index_col=0)\n",
    "    means = describe.loc['mean'].values.reshape(1, 1, 9)\n",
    "    stds = describe.loc['std'].values.reshape(1, 1, 9)\n",
    "    descaler = lambda x: x * stds + means\n",
    "    scaler = lambda x: (x - means) / stds\n",
    "    model = SCIModule(**model_kwargs)\n",
    "    pre = prediction(ckpt_path, model, vals, model_kwargs['lPre'], model_kwargs['lGet'])\n",
    "    pre = descaler(pre.transpose())\n",
    "    return pre\n",
    "    \n",
    "    \n",
    "def prediction(ckpt_path, model, data, lPre=42, lGet=84):\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    model.freeze()\n",
    "\n",
    "    data = data.reshape(1, 9, lGet)\n",
    "    x = torch.from_numpy(data).to(torch.float32)\n",
    "    y = model(x)\n",
    "    y = y.numpy().squeeze()\n",
    "    return y\n",
    "\n",
    "kwargs = {'features': 9,\n",
    "        'lPre': 6,\n",
    "        'lGet' : 18,\n",
    "        'Tree_levels':2,\n",
    "        'hidden_size_rate':6,\n",
    "        'loss':F.l1_loss,\n",
    "        'lr':1e-3,\n",
    "        'descaler':None}\n",
    "    \n",
    "pre = preHandler('./lightning_logs/fujiang_all/checkpoints/last.ckpt', \n",
    "                './original_data/05-涪江/涪江水质断面水质-小时尺度/两河审核数据查询表.xls',\n",
    "                '2021-04-12', kwargs, \n",
    "                './all_data/fujiang_1d/all_describe.csv', data_factory, 3, 5, 3)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882a8eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lPre, lGet = 42, 84\n",
    "features = data.shape[1]\n",
    "l, h = 25, 3\n",
    "\n",
    "window = 8000\n",
    "index = x[window:]\n",
    "real = data[window:, :]\n",
    "prediction = pre[window:, :]\n",
    "\n",
    "def plot(x, data, pre, area=9000, lGet=84):\n",
    "    fig, axis = plt.subplots(features, 1, figsize=(l, h*features), constrained_layout=True)\n",
    "\n",
    "    for i in range(features):\n",
    "        name = en_keys[i]\n",
    "        axis[i].plot(x[:], data[:, i], '-k', linewidth=3)\n",
    "        axis[i].plot(x[lGet:area+lGet], pre[:area, i], '-r', linewidth=0.8)\n",
    "        axis[i].plot(x[area+lGet:], pre[area:, i], '-b', linewidth=0.8)\n",
    "\n",
    "    #     df.plot(y=k, ax=axis[i], style='-k')\n",
    "    #     df.plot(y=f'{k}(pre)', ax=axis[i], style='--r')\n",
    "\n",
    "        axis[i].set_title(name, fontsize=20)\n",
    "        axis[i].set_xlabel('', fontsize=15)\n",
    "        axis[i].set_ylabel('', fontsize=15)\n",
    "\n",
    "        axis[i].legend([name], fontsize=15)\n",
    "    \n",
    "plot(index, real, prediction, 9000-window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Do Not remove !!!\n",
    "# Data Handler for BianJie, FuJiang, luguhu.\n",
    "dataHandler('./original_data/04-四川省边界断面/四川边界断面水质数据/', 30, 6, './all_data/bianjie_1d/', data_factory, 3, 5, 3)\n",
    "dataHandler('./original_data/泸沽湖邛海鲁班水库水质数据/原始查询/', 30, 6, './all_data/luguhu_1d/', data_factory, 3, 5, 3)\n",
    "dataHandler('./original_data/05-涪江/涪江水质断面水质-小时尺度/', 30, 6, './all_data/fujiang_1d//', data_factory, 3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Do Not remove !!!\n",
    "# Data Handler for MinTuoJiang data\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from utils import _gen_data\n",
    "lPre, lGet = 6, 18\n",
    "r, limit, step = 3, 5, 3\n",
    "save_path = './all_data/mtj_1d/'\n",
    "ptj_keys = ['监测时间', '水温(℃)', 'pH值(无量纲)', '溶解氧(mg/L)', '电导率(uS/cm)', '浊度(NTU)','高锰酸盐指数(mg/L)',\n",
    "           '氨氮(mg/L)', '总磷(mg/L)', '总氮(mg/L)']\n",
    "p = Path('./original_data/08-岷沱江数据/岷沱江水质监测数据/')\n",
    "d = {}\n",
    "for file in p.iterdir():\n",
    "    name = re.match('\\d*?\\D+', file.stem)[0]\n",
    "    if name in d.keys():\n",
    "        d[name].append(file)\n",
    "    else:\n",
    "        d[name] = [file]\n",
    "all_df = []\n",
    "all_data = []\n",
    "for k in tqdm(d.keys()):\n",
    "    dfs = []\n",
    "    for file in d[k]:\n",
    "        df = pd.read_excel(file, header=1, usecols=ptj_keys, index_col=0, dtype=str)\n",
    "        df.drop(df.index[0], axis=0, inplace=True)\n",
    "        dfs.append(df)    \n",
    "    df = pd.concat(dfs)\n",
    "    df = df.sort_index()\n",
    "    df.index=pd.to_datetime(df.index, format='%Y-%m-%d %H:%M:%S')\n",
    "    for f in df.keys():\n",
    "        df[f] = df[f].str.extract('(^\\d+\\.\\d+)')\n",
    "    df = df.astype('float64')\n",
    "    df = df.resample('4H').mean()\n",
    "    df.loc[(df==0).all(axis=1)] = np.nan    \n",
    "    df = remove_outliers(df, standard_deviation, 25)\n",
    "    df[df < 0] = np.nan\n",
    "    df = patch_up(df, r, limit)\n",
    "    df = smooth(df, step)\n",
    "    \n",
    "    all_df.append(df)\n",
    "    \n",
    "    save_file_name = f'{save_path}{k}'\n",
    "    describe_save_name = f'{save_file_name}_describe.csv'\n",
    "    x = _gen_data(df, lGet, lPre, save_file_name)\n",
    "    all_data.append(x)\n",
    "    df.describe().to_csv(describe_save_name)\n",
    "\n",
    "all_data = np.vstack(all_data)\n",
    "np.save(f'{save_path}all',all_data)\n",
    "pd.concat(all_df).describe().to_csv(f'{save_path}all_describe.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'./original_data/04-四川省边界断面/四川边界断面水质数据/':'./all_data/bianjie_1d/', \n",
    "       './original_data/05-涪江/涪江水质断面水质-小时尺度/':'./all_data/fujiang_1d/', \n",
    "       './original_data/泸沽湖邛海鲁班水库水质数据/原始查询/':'./all_data/luguhu_1d/',}\n",
    "def merge_all(path_dict, lGet, lPre):\n",
    "    for path in path_dict.keys():\n",
    "        p = Path(path)\n",
    "        save_path = path_dict[path]\n",
    "        nouse = [f.unlink() for f in Path(save_path).iterdir() if f.is_file()]\n",
    "        dfs = []\n",
    "        data = []\n",
    "        print(p)\n",
    "        for file in p.iterdir():\n",
    "            dfs.append(data_factory(file, 3, 5, 3))\n",
    "            save_file_name = f'{save_path}{file.stem}'\n",
    "            describe_save_name = f'{save_path}{file.stem}_describe.csv'\n",
    "            data.append(_gen_data(df, lGet, lPre, save_file_name))\n",
    "            df.describe().to_csv(describe_save_name)\n",
    "        \n",
    "        describe = pd.concat(dfs).describe()\n",
    "        describe.to_csv(f'{save_path}all_describe.csv')\n",
    "        np.save(f'{save_path}all', np.vstack(data, ))\n",
    "    return \n",
    "merge_all(dic, 18, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9937f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'./original_data/04-四川省边界断面/四川边界断面水质数据/':'./all_data/bianjie/', \n",
    "       './original_data/05-涪江/涪江水质断面水质-小时尺度/':'./all_data/fujiang/', \n",
    "       './original_data/泸沽湖邛海鲁班水库水质数据/原始查询/':'./all_data/luguhu/',}\n",
    "\n",
    "def save_all_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "21d59fe64bae991edae597942ebf1cba238720968e9671d529a1841577ba01b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
